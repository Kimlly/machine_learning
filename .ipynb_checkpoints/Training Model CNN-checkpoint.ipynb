{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f22f76ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y Kimly\n",
    "# ITE G8 A\n",
    "# Animal Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99435ef",
   "metadata": {},
   "source": [
    "#Model and Training\n",
    "\n",
    "This is a crucial step where the methods are used to identify the most interesting patterns of the image, features that might be unique to a particular class and that will, later on, help the model to differentiate between different classes. This process where the model learns the features from the dataset is called model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17278dfb",
   "metadata": {},
   "source": [
    "- Import the variable that store in the computing machine back to use and convert the data value to a smaller number to make it more convenience for computing since the image is in a color pixel of RGB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "712310e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle    # import the variable to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f96a011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pickle.load(open('x.pkl','rb'))    # open to read\n",
    "y = pickle.load(open('y.pkl','rb'))    # open to read "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d76e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x/255        # convert data value to between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc91ed78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312, 100, 100, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape          # check the view of dataset  8000 image weight and height 100*100 3 channel of RGB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa9e360",
   "metadata": {},
   "source": [
    "- **Keras** is used to make the implementation of neural networks easy.\n",
    "- **Convolutional layers** are the major building blocks used in convolutional neural networks. A convolution is the simple application of a filter to an input that results in an activation. Repeated application of the same filter to an input result in a map of activations called a feature map, indicating the locations and strength of a detected feature in an input, such as an image. A 2-D convolutional layer applies sliding convolutional filters to 2-D input. The layer convolves the input by moving the filters along the input vertically and horizontally and computing the dot product of the weights and the input, and then adding a bias term. \n",
    "- **ReLU layer** stands for the rectified linear unit. Once the feature maps are extracted, the next step is to move them to a ReLU layer. It’s performing an element-wise operation and sets all the negative pixels to 0. It introduces non-linearity to the network, and the generated output is a rectified feature map.\n",
    "- **A pooling layer** is another essential building block of CNN. It tries to figure out whether a particular region in the image has the feature we are interested in or not. Pooling has the advantage of making the representation more compact by reducing the spatial size of the feature maps, thereby reducing the number of parameters to be learnt. Pooling reduces only the height & width of the feature map, not the (i.e., number of channels). For example, if we have ‘m’ feature maps each of size (c, c), the pooling operation will produce ‘m’ outputs (c/2, c/2). \n",
    "- **Max pooling** – If any of the patches say something firmly about the presence of a particular feature, then the pooling layer counts that feature as ‘detected’.\n",
    "- **Flattening** is used to convert all the resultant 2-Dimensional arrays from pooled feature maps into a single long continuous linear vector. The flattened matrix is fed as input to the fully connected layer to classify the image.\n",
    "- **Dense Layer** is simple layer of neurons in which each neuron receives input from all the neurons of previous layer, thus called as dense. Dense Layer is used to classify image based on output from convolutional layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea2f0699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential      # keras is used to make the implementation of neural networks easy \n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "202f17b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()   # Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n",
    "\n",
    "model.add(Conv2D(64,(3,3), activation = 'relu'))  # feature detector with 64 convolution layer and 3*3 matric , activation function \"relu\"\n",
    "model.add(MaxPooling2D((2,2))) # 2*2 matric  Activation function decides whether a neuron should be activated or not by calculating the weighted sum and further adding bias to it\n",
    "\n",
    "model.add(Conv2D(64,(3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Flatten())                    # flatten layer is to set data into array with a single one dimensional metric\n",
    "\n",
    "model.add(Dense(128, input_shape = x.shape[1:],activation = 'relu')) #Dense is the neural network layer with 128 nueron in the shape of size from array index 1 in the shape array above\n",
    "\n",
    "model.add(Dense(2,activation = 'softmax')) #output with 2 neuron of cat and dog / activation function softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839c2a92",
   "metadata": {},
   "source": [
    "- tf.keras.optimizers.Adam optimizer and tf.keras.losses.SparseCategoricalCrossentropy loss function to view training and validation accuracy for each training epoch, pass the metrics argument to model.compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d86a0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer ='adam',loss ='sparse_categorical_crossentropy',metrics = ['accuracy'])\n",
    "\n",
    "# loss function and optimizer  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212ce2fd",
   "metadata": {},
   "source": [
    "- Train model for 5 epochs by fit our model with the dataset\n",
    "- Validation_split is how much we keep our dataset for testing to validate the model\n",
    "- Epoch is one complete pass of the training dataset thorough the algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "019cf241",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "9/9 [==============================] - 5s 418ms/step - loss: 1.4762 - accuracy: 0.4821 - val_loss: 0.6978 - val_accuracy: 0.4062\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 2s 189ms/step - loss: 0.6924 - accuracy: 0.5036 - val_loss: 0.7006 - val_accuracy: 0.4062\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.6835 - accuracy: 0.5893 - val_loss: 0.7519 - val_accuracy: 0.4375\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.6247 - accuracy: 0.6286 - val_loss: 0.7023 - val_accuracy: 0.5938\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 1s 153ms/step - loss: 0.5601 - accuracy: 0.7571 - val_loss: 0.8061 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x,y,epochs = 5, validation_split = 0.1, )\n",
    "#fit our model with the dataset\n",
    "# validation_split is how much we keep our dataset for testing to validtae the model\n",
    "# epoch is one complete pass of the training dataset thorugh the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00006572",
   "metadata": {},
   "source": [
    "#References\n",
    "\n",
    "(6219) Image Classification with Keras, Tensorflow | Cat Vs Dog Prediction | Convolution Neural Networks P1 - YouTube\n",
    "(6219) Image Classification with Keras, Tensorflow | Cat Vs Dog Prediction | Convolution Neural Networks P2 - YouTube\n",
    "<https://www.analyticsvidhya.com/blog/2022/01/convolutional-neural-network-an-overview/>\n",
    "<https://keras.io/guides/sequential_model/>\n",
    "https://www.simplilearn.com/tutorials/deep-learning-tutorial/what-is-keras>\n",
    "<https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.convolution2dlayer.html>\n",
    "https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/>\n",
    "<https://www.simplilearn.com/tutorials/deep-learning-tutorial/convolutional-neural-network>\n",
    "https://www.google.com/search?q=dense+layer+in+cnn&oq=dense&gs_lcrp=EgZjaHJvbWUqCQgJEAAYQxiKBTIGCAAQRRg5MgcIARAAGIAEMgcIAhAAGIAEMgcIAxAAGIAEMgcIBBAAGIAEMgcIBRAAGIAEMgcIBhAAGIAEMgcIBxAAGIAEMgkICBAAGEMYigUyCQgJEAAYQxiKBdIBCDQ2MjdqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ca8acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
